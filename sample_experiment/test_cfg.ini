[ENVIRONMENT]
# environment settings
GPU_ID = 3
MLFLOW_TRACKING_URI = mysql://127.0.0.1:3306/mlflow_experiments
OVERALL_EXCEL_STAT_SAVE_PATH = /ext_vol/test_api_test/test_results

[EXPERIMENT METADATA]
# integer
EXP_NAME = Mobius_release_test_2
RUN_NAME = run_at_20191010_930

[TEST DATA]
# test data and data summary excel path
# no subfolder in the folder with test data
# data summary excel format: one line per test case, with
# columns: file_name, meta_<metadata>, gt_<class/variable label>

# IMPT: meta_, gt_, p_ prefixes are reserved.

# ########## data type = video or image ###########
TEST_DATA_TYPE = video
# #################################################

TEST_DATA_PATH = ./mobius_perf_test_v1.0/test_set/
TEST_DATA_ROI_PATH = ./mobius_perf_test_v1.0/test_set_ROI/
DATA_SUMMARY_EXCEL_PATH = ./mobius_perf_test_v1.0/mobius_test_data_summary_truc.xlsx

# for detection ground truth saved as xml file
# set path = none if ground truth is in data summary
ANNOTATION_PATH = none

[VAS SOFTWARE]
# require a predict.py file that contains a Predictor() class with model_init and model_infer methods
# model_init method returns an active session for model_infer
# model_infer use the active session repeatly for each of the test data
# remember to reset counter in model_infer method

# IMPT: model_infer method returns dict that has key format 'p_<class/variable label>'
# other metadata returned shall have key format 'meta_<metadata>'

PATH = /ext_vol/test_api_test/mobius/

[PARAMS]
# TODO: training parameters to be recorded
LEARNING_RATE
CONV_KERNEL_SIZE

[METRICS]
# metrics to be evaluated, for each test case
EXPLAINED_VARIANCE_SCORE = 1
MEAN_AVERAGE_PRECISION = 0

# overall evaluation metrics is defined here, they will be evaluate across all test cases
OVERALL_F1_SCORE = 1
OVERALL_EXPLAINED_VARIANCE_SCORE = 1
